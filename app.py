import streamlit as st
import pandas as pd
from langchain_huggingface import HuggingFaceEndpoint

# ===============================
# Configuraci√≥n de la p√°gina
# ===============================
st.set_page_config(page_title="App de An√°lisis", layout="wide")

# ===============================
# Inicializaci√≥n de variables de sesi√≥n
# ===============================
if "df" not in st.session_state:
    st.session_state.df = None
if "hf_token" not in st.session_state:
    st.session_state.hf_token = None
if "llm" not in st.session_state:
    st.session_state.llm = None

# ===============================
# Funci√≥n para construir el modelo LLM
# ===============================
def build_llm(hf_token):
    return HuggingFaceEndpoint(
        repo_id="meta-llama/Llama-3.2-1B-Instruct",  # puedes cambiar el modelo
        huggingfacehub_api_token=hf_token
    )

# ===============================
# Men√∫ de navegaci√≥n
# ===============================
st.sidebar.title("üìä Men√∫ de Navegaci√≥n")
menu = st.sidebar.radio("Ir a:", [
    "Carga de Datos",
    "An√°lisis de Tendencia",
    "An√°lisis de Correlaci√≥n",
    "An√°lisis con LLM"
])

# ===============================
# P√°gina: Carga de Datos
# ===============================
if menu == "Carga de Datos":
    st.header("üìÇ Carga de Datos")

    # Subida de archivo
    uploaded_file = st.file_uploader("Sube un archivo CSV", type="csv")
    if uploaded_file is not None:
        st.session_state.df = pd.read_csv(uploaded_file)
        st.success("‚úÖ Archivo cargado exitosamente")
        st.dataframe(st.session_state.df.head())

    # Ingreso de Token Hugging Face
    token_input = st.text_input("üîë Ingresa tu Hugging Face Token", type="password")
    if token_input:
        st.session_state.hf_token = token_input
        st.success("‚úÖ Token guardado en la sesi√≥n")

# ===============================
# P√°gina: An√°lisis de Tendencia
# ===============================
elif menu == "An√°lisis de Tendencia":
    st.header("üìà An√°lisis de Tendencia")
    if st.session_state.df is not None:
        st.line_chart(st.session_state.df.select_dtypes(include="number"))
    else:
        st.warning("‚ö†Ô∏è Primero carga un dataset en 'Carga de Datos'.")

# ===============================
# P√°gina: An√°lisis de Correlaci√≥n
# ===============================
elif menu == "An√°lisis de Correlaci√≥n":
    st.header("üìä An√°lisis de Correlaci√≥n")
    if st.session_state.df is not None:
        corr = st.session_state.df.corr(numeric_only=True)
        st.dataframe(corr)
        st.bar_chart(corr)
    else:
        st.warning("‚ö†Ô∏è Primero carga un dataset en 'Carga de Datos'.")

# ===============================
# P√°gina: An√°lisis con LLM
# ===============================
elif menu == "An√°lisis con LLM":
    st.header("ü§ñ An√°lisis con LLM")

    if st.session_state.df is not None and st.session_state.hf_token:
        # Cargar modelo solo una vez
        if st.session_state.llm is None:
            with st.spinner("Cargando modelo LLaMA desde Hugging Face..."):
                st.session_state.llm = build_llm(st.session_state.hf_token)

        # Entrada de usuario
        user_query = st.text_area("Escribe tu consulta sobre los datos")
        if st.button("Analizar con LLM") and user_query:
            prompt = f"""
            Dataset columnas: {', '.join(st.session_state.df.columns)}.
            Responde en espa√±ol de forma clara: {user_query}
            """
            response = st.session_state.llm.invoke(prompt)
            st.write("### Respuesta del LLM:")
            st.write(response.content)
    else:
        st.warning("‚ö†Ô∏è Primero carga un dataset y proporciona tu Hugging Face Token en 'Carga de Datos'.")
